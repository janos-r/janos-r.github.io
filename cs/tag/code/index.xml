<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Code | Radim</title><link>/cs/tag/code/</link><atom:link href="/cs/tag/code/index.xml" rel="self" type="application/rss+xml"/><description>Code</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>cs</language><lastBuildDate>Mon, 10 Aug 2020 00:00:00 +0000</lastBuildDate><image><url>/images/icon_hub89e7b28a6abff2b4ec084e6c0608a00_13774_512x512_fill_lanczos_center_2.png</url><title>Code</title><link>/cs/tag/code/</link></image><item><title>Exercism.io</title><link>/cs/project/exercism/</link><pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate><guid>/cs/project/exercism/</guid><description>&lt;h2 id="a-new-language">A new language&lt;/h2>
&lt;p>When I started learning Rust in the second half of 2019, I first read &amp;ldquo;
&lt;a href="https://doc.rust-lang.org/book/" target="_blank" rel="noopener">The Book&lt;/a>&amp;rdquo; from the official website. I can highly recommend it. It takes a little longer to get going and many people prefer to go right into writing code, but my first step into this very new territory was intentionally cautious and thorough. I spent my fair share of time on the book.&lt;/p>
&lt;h2 id="after-the-basics">After the basics&lt;/h2>
&lt;p>There is also &amp;ldquo;Rust by example&amp;rdquo; which is more hands on. I went through it after reading the book relatively quickly, it is also very well made. At this stage jumping on some exercises is the perfect time. Experimenting with different approaches to new problems and fighting the typical hurdles of a new programming language is ideal. Rust especially has a slightly higher learning curve than other languages that try to be more similar to each other. On the other hand, I only spent a lot of time on JavaScript before Rust, so I went into it with a still rather flexible mind. I&amp;rsquo;m sure that helped allot.&lt;/p>
&lt;h2 id="where-to-exercise">Where to exercise&lt;/h2>
&lt;p>When learning JavaScript, I also used to do some exercises on pages like
&lt;a href="https://codecademy.com" target="_blank" rel="noopener">codecademy.com&lt;/a>,
&lt;a href="https://codingame.com" target="_blank" rel="noopener">codingame.com&lt;/a> and
&lt;a href="https://codewars.com" target="_blank" rel="noopener">codewars.com&lt;/a>. All of them are wonderful and totally free options for beginners. Especially codewars seamed to provide close to unlimited content and a great way how to compare solutions with others. It&amp;rsquo;s really amazing how many good and free options there are to learn and improve at coding.&lt;/p>
&lt;h2 id="exercism">Exercism&lt;/h2>
&lt;p>In the Rust community, I heard recommendations about
&lt;a href="https://exercism.io" target="_blank" rel="noopener">exercism.io&lt;/a>. That&amp;rsquo;s where I first found the page. I can&amp;rsquo;t praise this website enough. I spent a few months around the end of 2019, doing exercises in Rust several times a week. At that time, I was able to get real reviews by mentors on the page, guiding me through the solutions. Later when the language became more popular, there were not enough mentors to give direct reviews. It was still possible to progress through an &amp;ldquo;unguided&amp;rdquo; track though and compare your solutions to those from other users.&lt;/p>
&lt;h2 id="final-thoughts">Final thoughts&lt;/h2>
&lt;p>By the time of writing, I don&amp;rsquo;t spend much time on Rust anymore. I have two other goals that I want to reach by the end of the year. But If I get the itch to play around with some Rust again, I still left some untouched exercises on the page and I&amp;rsquo;m sure I would have some good fun with it, while also learning some new practices and ways to think about coding.&lt;/p>
&lt;h3 id="ps">PS&lt;/h3>
&lt;p>At the beginning on this website, the picture slider, the second picture that is saying &amp;ldquo;Developer&amp;rdquo;. That background was my own screenshot, a little edited in gimp, from one of my last exercises on exercism.&lt;/p>
&lt;figure >
&lt;a data-fancybox="" href="/media/slider/code.png" >
&lt;img src="/media/slider/code.png" alt="" >
&lt;/a>
&lt;/figure></description></item><item><title>API in Rust</title><link>/cs/project/graphql_rust/</link><pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate><guid>/cs/project/graphql_rust/</guid><description>&lt;h2 id="db-experience">DB experience&lt;/h2>
&lt;p>During my 2 years of self study between 2017-2019, I spent a few months studying MongoDB. At that time, it was recommended as a good technology for the web. I knew some basic SQL, and I spent some time with SQLite in a Python project tutorial during my study, but MongoDB was a database that I really put in some effort and finished the free certificates that they have on their official website. I have to say that I like MongoDB, and I was lucky to find my current company starting 2019, where MongoDB is used exclusively.&lt;/p>
&lt;h2 id="day-job">Day job&lt;/h2>
&lt;p>Most of my work is focused on the backend of a big portal website for users and admins. Specifically, the creation and maintenance of APIs. Written in TypeScrip, stored in MongoDB and served with GraphQL. GraphQL was new to me when I started in the company, but once I got used to it, serving data via REST feels like some totally antiquated. Of course, we also use REST for necessary things, but the type safety of GraphQL and the schemas is something amazing.&lt;/p>
&lt;h2 id="rust">Rust&lt;/h2>
&lt;p>During 2019, I wanted to learn a new programming language. Most of my time 2017-2019 I spent learning JavaScript. I spent a some time on C and Python too. I like python, but I already did a small project with it, some intermediate tutorials, and although I definitely could learn much more in Python, It didn&amp;rsquo;t really feel challenging enough and I wanted something that would push my knowledge as a developer. C was interesting, but way too hard for me to spend too much time on it. I wanted something practical and modern. The purpose was to learn to be a better programmer, but I felt like I would spend too much time on suffering while trying to build something in C. A colleague at work started to learn GOlang a little. I felt tempted to read up on it a little and stumbled upon this wave of new programming languages growing in 2019 like go, rust or julia. Julia felt too esoteric to me and GO somehow too popular to be cool. But when I was reading about Rust and their attempt to make memory management like in C accessible and safe for even beginner programmers, I was very intrigued. I don&amp;rsquo;t regret my choice in Rust a bit. It was exactly what I was looking for. Something more challenging on a technical level, but also holding your hand in the process, making for a great learning experience.&lt;/p>
&lt;p>First I read &amp;ldquo;The book&amp;rdquo; from the official website. The book took a while, but it is very good. I prefer taking my time while studying anything and go step by step a bit every day. So I didn&amp;rsquo;t mind the length of the book. After maybe a few months, I started with tutorials on Exercism. It is an amazing website and I might make an article about it exclusively in the future.&lt;/p>
&lt;h2 id="project">Project&lt;/h2>
&lt;p>After a few weeks / months of tutorials, I felt the need to try something personal. It doesn&amp;rsquo;t need to be something production-ready, I just wanted to try to put together something new. I soon began thinking if my favorite MongoDB + GraphQL could work with Rust. I found an article from 2018 that looked a little scary, but when reading the docs of the GraphQL library for Rust, I realized 2018 might be already old information.&lt;/p>
&lt;p>I made the simple web API by the end of 2019. I will not be talking about the technical specifics of the project and its libraries. Under the link above, in the project&amp;rsquo;s readme.md, you can find the technical details. I also left plenty of comments in the code itself for me or anybody else if you are interested. But below are some memories that I have of the experience writing it.&lt;/p>
&lt;h2 id="rust-with-mongodb">Rust with MongoDB&lt;/h2>
&lt;p>The library for MongoDB could have been better. I remember thinking that using MongoDB in TypeScript with Mongoose is honestly a much better experience. In rust, the objects have to be translated through a parsing library like Serde. But I guess this is not an issue exclusive to Rust, more like a benefit when using JavaScript with JSON. It was not trivial, but possible!&lt;/p>
&lt;h2 id="rust-with-graphql">Rust with GraphQL&lt;/h2>
&lt;p>The library for GraphQL on the other hand was surprisingly nice to use. I loved how it used macros and simple Rust structs to generate its necessary objects. It was easy to create the schemas, much nicer than I remembered from the crazy 2018 article. I remember being amazed that I could easily recommend this, even though I&amp;rsquo;m not a programming veteran, and I am writing this in Rust, supposedly one of the fastest and most powerful languages out there.&lt;/p>
&lt;h2 id="final-thoughts">Final thoughts&lt;/h2>
&lt;p>So, I was very happy when this was running. Later I changed the module tree and I implemented logging. Both simply for experience and making the project feel a little more complete, even though this was basically more like a proof of concept. A challenge for myself.&lt;/p>
&lt;h2 id="would-i-change-it">Would I change it?&lt;/h2>
&lt;p>I imagine that in the past 7 months since then, both libraries got only better. I didn&amp;rsquo;t look at them since then. Also, I had a hard time to choose the web server library. I tried several till I stuck with Iron. Were I to do it over, at this time of writing, I would probably use Actix-web instead. But the library landscape of Rust is evolving quickly and it&amp;rsquo;s no surprise that there are many changes. I will not touch this project again. It serves as the memory of my experience from that time. My first personal github project.&lt;/p></description></item><item><title>Circle CI/CD</title><link>/cs/project/circle/</link><pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate><guid>/cs/project/circle/</guid><description>&lt;p>In my company, we are using AKS (Azure Kubernetes Service). With every git commit to the master branch, a new docker image is build and pushed to the repository with CircleCI. It is automatically deployed to the dev cluster. At a controlled release moment, we are then able to release all necessary docker images with their particular versions in one go to the production cluster using helm.&lt;/p>
&lt;p>The project is quite big and all connected parts are quite complicated in their setup. That&amp;rsquo;s why I wanted to create my own small project and learn how to set up a similar CI/CD (circular integration / circular deployment).&lt;/p>
&lt;p>I did so June 2020. Link to the project above. Journey description below.&lt;/p>
&lt;h2 id="what-to-push">What to push&lt;/h2>
&lt;p>First decision was &lt;strong>what&lt;/strong> to build and push. I made a simple website with the static site generator
&lt;a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo&lt;/a>. It was the first time I made a web with hugo, so this was in itself a very good learning experience. I stuck literary to the &amp;ldquo;quick start&amp;rdquo; guide to not lose too much time with this step, since the page itself is obviously not the goal of this project. But in general, I can only recommend Hugo.&lt;/p>
&lt;h2 id="script-before-circle">Script before circle&lt;/h2>
&lt;p>Obviously I wanted to use the same technologies that we are using on the company project. I was eager to get into CircleCI, but I quickly realized that is not the right approach. It turns out that the best approach for me was to leave the CI as the absolute last step. First make a long list of all the cli commands that you find useful. I put most of them in the readme.md of the project. This is not &amp;ldquo;best practice&amp;rdquo; for a readme, but I well, it was meant to be just my personal learning project and I wanted to have the commands visible. Only after you can do everything with your cli commands from beginning to end, then it makes sense to put it in a CI config.&lt;/p>
&lt;h2 id="docker">Docker&lt;/h2>
&lt;p>So first thing, I made my first successful docker image build. After running it with a port-forward and seeing that the Dockerfile took the correct content and I saw the page loaded in the browser, I have to say it feels good.&lt;/p>
&lt;p>build image:&lt;br>
&lt;code>docker build -t radimj/repo1 .&lt;/code>&lt;/p>
&lt;p>run and forward port to localhost:&lt;br>
&lt;code>docker run -d -p 80:80 radimj/repo1&lt;/code>&lt;/p>
&lt;h2 id="docker-repository">Docker repository&lt;/h2>
&lt;p>Next step, where to push the image? Unfortunately, you can&amp;rsquo;t treat docker images like ISOs or packages as the word &amp;ldquo;image&amp;rdquo; would suggest. There are command like &amp;ldquo;save&amp;rdquo; and &amp;ldquo;export&amp;rdquo;, you can look up the details yourself, but the main takeaway is that docker images are not meant to be sent around as packaged files. You have to use a repository. I saw guides for creating local repositories, but again, this is not the main purpose dockers exist. You simply should use a remote repository. You can store them on Azure too, but I didn&amp;rsquo;t have a free account there, so I just went with the simplest solution, I made a private
&lt;a href="https://hub.docker.com/" target="_blank" rel="noopener">DockerHub&lt;/a> account.&lt;/p>
&lt;p>Another a little unexpected process is that you don&amp;rsquo;t add the repository through some &amp;ldquo;add repo&amp;rdquo; or something, you have to &lt;code>docker login&lt;/code>. This will hash the login details in ~/.docker/config.json. As far as I know, that is the only place you can find out what repository your docker is using. After that, you have to make sure your image name (tag) that corresponds to your account and repository name, else it wouldn&amp;rsquo;t know where in your repository to add the image. After that, a simple push should work.&lt;/p>
&lt;p>push to docker hub:&lt;br>
&lt;code>docker push radimj/repo1&lt;/code>&lt;/p>
&lt;p>I&amp;rsquo;m noticing I&amp;rsquo;m being unnecessarily detailed and this project had so many small issues that this would end up being a little book. I will be more concise bellow.&lt;/p>
&lt;h2 id="circleci">CircleCI&lt;/h2>
&lt;p>Since I didn&amp;rsquo;t have a remote kubernetes cluster to push to, I was satisfied if my CI would just build the image and push it to the repository. The details of the CI config are in the &lt;code>/.circleci/config.yml&lt;/code> you can find it in the project. I kept it as simple as possible. A few notable points:&lt;/p>
&lt;ul>
&lt;li>Base image&lt;br>
It takes a moment to choose a fitting base docker image, that is used for the whole CI process.&lt;/li>
&lt;li>Docker&lt;br>
Use docker with &amp;ldquo;- setup_remote_docker&amp;rdquo;. This creates a special environment that the CI uses to work with docker.&lt;/li>
&lt;li>CLI tool&lt;br>
Circle CI has a cli tool that lets you run the build locally. This is good to speed up the creation of the config, but don&amp;rsquo;t rely on it too much. For example the &amp;ldquo;setup_remote_docker&amp;rdquo; command didn&amp;rsquo;t work for me with it and I had to use &amp;ldquo;sudo&amp;rdquo; for the docker commands when running the cli localy.&lt;/li>
&lt;li>SSH into the build&lt;br>
When something breaks only remotely and you don&amp;rsquo;t know why, a last resort is SSH into the CI build. This was an interesting experience. It took a moment to set up, but if you just follow the guide in the docs you should be fine. I managed to get into the docker image that was sitting broken in the remote CI build where I found what was missing.&lt;/li>
&lt;/ul>
&lt;p>Being able to set up CircleCI was an empowering experience. CI really gives you the feeling like &amp;ldquo;set up once, never touch again&amp;rdquo;. When you first write it, the &amp;ldquo;never touch again&amp;rdquo; feels very good. But after some time, when you forget why you added this or that line&amp;hellip; &amp;ldquo;never touch again&amp;rdquo; can become scary ðŸ˜‚&lt;/p>
&lt;h2 id="kubernetes">Kubernetes&lt;/h2>
&lt;p>Kubernetes can be easily tested with Minikube, or similar tools that run a single node cluster on your local drive. Setting up a production ready Kubernetes on a private server is much harder than I expected. It is not like installing nginx or a machine and expecting it to work. I read there are ways how to do it, but for now that is beyond me. Production ready Kubernetes clusters are best chosen from established providers online. After realizing this, being able to use something like Minikube (or others) is a really amazing thing, since it behaves like a real cluster and is perfect for learning and basic testing.&lt;/p>
&lt;p>In Kubernetes, everything is about deployment setups within .yaml files. You can write them by hand, or export them from a running deployment / service / pod with &amp;ndash;output yaml. The Kubernetes documentation is quite good, and every single of my steps here is better explained there. So I will not be rewriting the docs here. Rather, I will show you the process how I put brick on brick with small commands to get to a better understanding of the result.&lt;/p>
&lt;p>First, you need to set up a secret in kubernetes that will be used for authorization when pulling docker images from repos. I did it from the docker login file:&lt;/p>
&lt;pre>&lt;code>kubectl create secret generic regcred \
--from-file=.dockerconfigjson=&amp;lt;path/to/.docker/config.json&amp;gt; \
--type=kubernetes.io/dockerconfigjson
&lt;/code>&lt;/pre>
&lt;p>That can be tested by running once pod with the secret:&lt;br>
&lt;code>kubectl run repo1 --overrides='{ &amp;quot;spec&amp;quot;: { &amp;quot;imagePullSecrets&amp;quot;: [{&amp;quot;name&amp;quot;: &amp;quot;regcred&amp;quot;}] } }' --image=radimj/repo1 --port=80&lt;/code>
The &amp;ldquo;overrides&amp;rdquo; functionality makes more sense when already knowing how a standard yaml config would look like. It is basically just editing a default one.&lt;/p>
&lt;p>The following commands give a way how to look into your pod. In my pod there is nginx exposing my website on port 80.&lt;/p>
&lt;p>forward or expose pod:&lt;br>
&lt;code>kubectl port-forward repo1 8080:80&lt;/code>&lt;br>
&lt;code>kubectl expose pod repo1 --type=&amp;quot;NodePort&amp;quot;&lt;/code>&lt;/p>
&lt;p>Deployments and services. I will not give examples how to create them or explain in detail what they are. Consult the official docs for details. But in essence, deployments are a bundle of pods, and services are configs how these resources are exposed on ports. They are created in a similar way like pods. All ideally with yaml files. Once you have them running, you can observe them with these commands.&lt;/p>
&lt;p>expose deployment:&lt;br>
&lt;code>kubectl expose deployment circle-deployment --type=LoadBalancer&lt;/code>&lt;/p>
&lt;p>nodeport in:&lt;br>
&lt;code>kubectl get svc&lt;/code>
&lt;code>kubectl describe service repo1&lt;/code>&lt;/p>
&lt;p>exposed on:&lt;br>
&lt;code>(minikube ip):&amp;amp;nodePort&lt;/code>&lt;/p>
&lt;h2 id="kubernetes-yaml-management">Kubernetes Yaml management:&lt;/h2>
&lt;p>create new yaml file from:&lt;br>
&lt;code>kubectl get (deploy / svc / pod ) -o yaml&lt;/code>&lt;/p>
&lt;p>run pod / deployment from yaml:&lt;br>
&lt;code>kubectl apply --filename private_deploy.yaml&lt;/code>&lt;/p>
&lt;p>revert (delete) from yaml:&lt;br>
&lt;code>kubectl delete -f private_deploy.yaml&lt;/code>&lt;/p>
&lt;p>This is the roundabout way how to get to your yaml file. But a good learning experience.&lt;/p>
&lt;h2 id="json-parsing">JSON parsing&lt;/h2>
&lt;p>One of the most surprising discoveries on this project was
&lt;a href="https://stedolan.github.io/jq/" target="_blank" rel="noopener">JQ&lt;/a>. When you work with Kubernetes or Azure, you get quickly used to large JSON outputs in your terminal. Both tools have inbuilt ways how to make this more manageable. In Kubernetes, you can query most outputs with &lt;code>--output jsonpath=&amp;quot;&amp;quot;&lt;/code> this is one of the query languages for parsing json. Azure uses &amp;ldquo;JMESPath&amp;rdquo; which is not the same. Azure also uses &lt;code>--output table&lt;/code> heavily, to make things more readable. If you make scripts and you are working only with one tool, then it is probably recommendable to use the inbuilt query parsing tool.&lt;/p>
&lt;p>But let me tell you, to learn just one way that sits forever in your system, that you can use for any JSON string that enters your command line is a great thing! With JQ I was able to do things like:&lt;/p>
&lt;p>display docker login secret from kubectl:\&lt;/p>
&lt;pre>&lt;code>kubectl get secret regcred \
--output jsonpath=&amp;quot;{.data.\.dockerconfigjson}&amp;quot; | \
base64 --decode | \
jq &amp;quot;.auths | map(.auth)[0]&amp;quot; -r | \
base64 --decode
&lt;/code>&lt;/pre>
&lt;p>You can see the use of both &amp;ldquo;jsonpath&amp;rdquo; and &amp;ldquo;jq&amp;rdquo; here for comparison. The output tells you exactly what login your kubectl is using. Also, good to understand how the secrets are stored in kubernetes.&lt;/p>
&lt;h2 id="helm">Helm&lt;/h2>
&lt;p>Again, I won&amp;rsquo;t go into details, this post is long enough. But simply put, helm is a bundle of kubernetes yaml config files, also called &amp;ldquo;manifests&amp;rdquo;. With helm, you can create files that hold variable names and you can distribute these variable through your manifests. This creates a setup where you can have a hundred manifests with thousands of lines, but if they all run together in a setup, you can just put variable names into all of them and then adjust the variable in just one place. Making releases of big projects manageable. This bundle of manifests is called a &amp;ldquo;chart&amp;rdquo; in helm. You can also have full repositories of charts, but I will not be getting into that here.&lt;/p>
&lt;p>lint chart:&lt;br>
&lt;code>helm lint circle-chart/&lt;/code>&lt;/p>
&lt;p>In the bellow example, I am packaging the chart folder into a package. This is useful for distribution, but not necessary if you are running it from just one place. You can simply call the commands on the chart folder as well.&lt;/p>
&lt;p>build package:&lt;br>
&lt;code>helm package circle-chart/&lt;/code>&lt;/p>
&lt;p>install: (name should be same as package name)&lt;br>
&lt;code>helm install circle circle-0.2.0.tgz&lt;/code>
&lt;code>helm install circle circle-chart/&lt;/code>&lt;/p>
&lt;p>check release:&lt;br>
&lt;code>helm ls&lt;/code>&lt;/p>
&lt;p>uninstall totally:&lt;br>
&lt;code>helm uninstall circle&lt;/code>&lt;/p>
&lt;h3 id="rolling-update">rolling update:&lt;/h3>
&lt;p>The following command changes only necessary pods, it does not update to &amp;ldquo;latest&amp;rdquo;
&lt;code>helm upgrade --install circle circle-chart/&lt;/code>&lt;/p>
&lt;p>if you want to change &amp;ldquo;latest&amp;rdquo; tags, old way was:
&lt;code>helm upgrade --install --recreate-pods circle circle-chart/&lt;/code>
new way is to add a random annotation in metadata:&lt;/p>
&lt;pre>&lt;code> annotations:
# creates a random 5-letter word, causing the pods to be recreated
rollme: {{ randAlphaNum 5 | quote }}
&lt;/code>&lt;/pre>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>Setting up a CI/CD flow is not a new thing. Jenkins was released 2011, that&amp;rsquo;s like a millennium in the tech world. The concept of container images is not new either, but it is undeniable that Docker containers are on a big wave right now and related solutions like Kubernetes and Helm are pulled along. In this project, I&amp;rsquo;m showing that anything, when taken piece by piece, can be learned. And why not learn the basics of the biggest wave in the current tech ocean?&lt;/p></description></item></channel></rss>